{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-25T16:52:49.218622Z","iopub.execute_input":"2023-02-25T16:52:49.219168Z","iopub.status.idle":"2023-02-25T16:52:49.231090Z","shell.execute_reply.started":"2023-02-25T16:52:49.219121Z","shell.execute_reply":"2023-02-25T16:52:49.229782Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/competicao-dois-ic/train.csv\n/kaggle/input/competicao-dois-ic/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nimport numpy as np\nfrom sklearn.metrics._plot.confusion_matrix import confusion_matrix\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nimport pandas as pd\nfrom itertools import zip_longest\n\ntreino = pd.read_csv('/kaggle/input/competicao-dois-ic/train.csv')\nteste = pd.read_csv('/kaggle/input/competicao-dois-ic/test.csv')\n\n#print(treino)\n\ntextos = treino['text']\nclasse = treino['misogynous']\n\nx = pd.concat([textos], axis=1)\nx = x.dropna()\ny = classe\naloneWords = textos.str.lower().str.split() #colocar todas as palavras em minúsculo\n#print(aloneWords) \n\ndicionario = set()\n\nfor lista in aloneWords:\n  dicionario.update(lista) #monta um dicionario pra cada palavra do dataset\n\n#print(dicionario)\nprint(len(dicionario))\n\nwordPosition = dict(zip(dicionario, range(len(dicionario))))\n#print(wordPosition)\n\ndef vetorizeCountWords(texto, wordPosition):\n  vetor = [0] * len(wordPosition)\n  for word in texto:\n    if word in wordPosition:\n      position = wordPosition[word]\n      vetor[position] += 1\n  return vetor\n\nvetorText = [vetorizeCountWords(texto, wordPosition) for texto in aloneWords]\n\n#print(vetorText)","metadata":{"execution":{"iopub.status.busy":"2023-02-25T16:52:55.003536Z","iopub.execute_input":"2023-02-25T16:52:55.003917Z","iopub.status.idle":"2023-02-25T16:52:57.052846Z","shell.execute_reply.started":"2023-02-25T16:52:55.003885Z","shell.execute_reply":"2023-02-25T16:52:57.051803Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"24558\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nfrom sklearn.datasets import make_classification\n\n\nX_train, X_test, y_train, y_test = train_test_split(vetorText,y, test_size=0.20, random_state=0)\n\n#dt = DecisionTreeClassifier(max_depth=None, criterion='entropy', splitter='random', min_impurity_decrease= 0.000000001, max_leaf_nodes= 100, random_state= 0)\n#dt = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\ndt = MLPClassifier(solver='sgd', alpha=1e-5, random_state=0, activation = 'tanh', learning_rate= 'adaptive')\n\ndt.fit(X_train, y_train)\n\nconf = confusion_matrix(y_test, dt.predict(X_test))\naccuracy = accuracy_score(y_test, dt.predict(X_test))\n\n#clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n\n#accuracy = predition.score(X_test, y_test)\n\nprint(conf)\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-02-25T16:52:59.673756Z","iopub.execute_input":"2023-02-25T16:52:59.674163Z","iopub.status.idle":"2023-02-25T17:06:48.409046Z","shell.execute_reply.started":"2023-02-25T16:52:59.674129Z","shell.execute_reply":"2023-02-25T17:06:48.405468Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n  ConvergenceWarning,\n","output_type":"stream"},{"name":"stdout","text":"[[587 169]\n [189 555]]\n0.7613333333333333\n","output_type":"stream"}]},{"cell_type":"code","source":"textos1 = teste['text']\n\n'''\nx1 = pd.concat([textos1], axis=1) #concatena em uma só tabela os valores númericos e categoricos pré-tratados\nx1 = x1.dropna()\n'''\n\naloneWords1 = textos1.str.lower().str.split() #colocar todas as palavras em minúsculo\n\n'''\ndicionario1 = set()\nfor lista in aloneWords1:\n  dicionario1.update(lista) #monta um dicionario pra cada palavra do dataset\n'''\n\nwordPosition1 = dict(zip(dicionario, range(len(dicionario))))\n\ndef vetorizeCountWords(texto1, wordPosition1):\n  vetor = [0] * len(wordPosition1)\n  for word in texto1:\n    if word in wordPosition1:\n      position = wordPosition1[word]\n      vetor[position] += 1\n  return vetor\n\nvetorText1 = [vetorizeCountWords(texto1, wordPosition1) for texto1 in aloneWords1]\n\ntab = dt.predict(vetorText1)\n\nsubmission = pd.DataFrame.from_records(zip_longest(teste['id'], tab), columns=['id', 'misogynous'])\nsubmission.set_index('id').to_csv('submission.csv')\nprint(submission)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T17:56:00.409685Z","iopub.execute_input":"2023-02-23T17:56:00.410057Z"},"trusted":true},"execution_count":null,"outputs":[]}]}